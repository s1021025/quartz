08/12/202311:22
Tags : 

# Self-Supervised Learning
---
## Model 

### Bert

#### Masking Input

![[Pasted image 20231208113119.png]]
#### Next Sentence Prediction
#### Sentence Order Prediction
# References

<iframe width="560" height="315" src="https://www.youtube.com/embed/gh0hewYkjgo?si=8TXQ0BxffLP1RUY9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
[1810.04805.pdf (arxiv.org)](https://arxiv.org/pdf/1810.04805.pdf)